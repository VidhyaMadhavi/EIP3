{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "3_lstm.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/VidhyaMadhavi/EIP3/blob/master/Session2_lstm_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wQ1-jg4n2Vx3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## Shared_link :  https://colab.research.google.com/drive/1zwz7wUNlpm1QpqShyco8C8de4mUdFnie"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C2OsXIpLkF-c",
        "colab_type": "text"
      },
      "source": [
        "## SESSION 2 - Assignment  - LSTM- RNN\n",
        "\n",
        "\n",
        "Go through this Post: https://machinelearningmastery.com/text-generation-lstm-recurrent-neural-networks-python-keras/\n",
        " (Links to an external site.)\n",
        " \n",
        "  Add these improvements to the final code described in the post: \n",
        "  - Predict 500 characters only\n",
        "  -  Remove all the punctuation from the source text\n",
        "  - Train the model on padded sequences\n",
        "   (Links to an external site.)\n",
        "   rather than random sequences of characters. \n",
        "  - Train the model for 100 epochs\n",
        "  -  Add dropout to the input layer, remove it from the layer before dense layer. Use Dropout value of 0.1 everywhere\n",
        "  - Submit!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "brIBsPOcz3oA",
        "colab_type": "text"
      },
      "source": [
        "## Approach Followed:\n",
        "\n",
        "- Removed the punctuation from the source\n",
        "- Divided the sentences with \\n\n",
        "- Find the unique characters and point them to numbers\n",
        "- Converted the sentences in to mapping numbers\n",
        "- Pad all the sentences\n",
        "- Prepare the train data - for every sentence the last characer is the output\n",
        "- Applied dropout in the input layer\n",
        "- Train the model for 100 epochs\n",
        "- Predict 500 characters  by passing 500 sentences"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4RpFS440j9wK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "7ab2c28e-7c35-41fa-a967-9ba5ff7e2904"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "import os\n",
        "os.chdir('/content/drive/My Drive/EIP3.0')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "seRIwfmikLdT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Dropout\n",
        "from keras.layers import LSTM\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from keras.utils import np_utils"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S7yfn3hckLww",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# load ascii text and covert to lowercase\n",
        "filename = \"wonderland.txt\"\n",
        "raw_text = open(filename).read()\n",
        "raw_text = raw_text.lower()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y4n66K3Ukf9B",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "2a47ffb1-4cbf-4875-ef3d-fdc965a2f3d2"
      },
      "source": [
        "print(type(raw_text))\n",
        "print(len(raw_text))"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'str'>\n",
            "144407\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HnK3ZVLVkiIW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# print(raw_text)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tN7-r9YnmCt0",
        "colab_type": "text"
      },
      "source": [
        "## Removing punctuation from the source"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uM5xyImJkmiG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "9450ec78-900b-454a-9e7f-df6a0b945654"
      },
      "source": [
        "from string import punctuation\n",
        "print(\"The following are the punctuation :\", punctuation)\n",
        "\n",
        "print(\"Removing the Punctuation and the displaying the result data\")\n",
        "def strip_punctuation(s):\n",
        "    return ''.join(c for c in s if c not in punctuation )\n",
        "\n",
        "raw_text = strip_punctuation(raw_text)"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The following are the punctuation : !\"#$%&'()*+,-./:;<=>?@[\\]^_`{|}~\n",
            "Removing the Punctuation and the displaying the result data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gcukAkjLk5aY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# print(raw_text)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_B11Voh-lKAK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "14853c76-4c65-4d80-cc5b-7f6713fb8d00"
      },
      "source": [
        "list_of_sentences = raw_text.split(\"\\n\")\n",
        "print(len (list_of_sentences))\n",
        "# print(len (list_of_sentences), list_of_sentences)"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "3337\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Ry2rh5-lhKN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "872d6f5e-1e88-4282-d7d8-2e0177d76efa"
      },
      "source": [
        "list_of_sentences_updated = []\n",
        "for i in list_of_sentences:\n",
        "  if len(i)> 0:\n",
        "    list_of_sentences_updated.append(i)\n",
        "print(len (list_of_sentences_updated))\n",
        "# print(len (list_of_sentences_updated), list_of_sentences_updated)"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2480\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7aZ0kJ8pmjOQ",
        "colab_type": "text"
      },
      "source": [
        "## Now convert these sentences in to sequence of number and prepare the training data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4CdEf32ClrV3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 510
        },
        "outputId": "f64453ba-49e2-4f45-dddc-71d650083ee5"
      },
      "source": [
        "sorted(list (set (' '.join(list_of_sentences_updated))))"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[' ',\n",
              " '0',\n",
              " '3',\n",
              " 'a',\n",
              " 'b',\n",
              " 'c',\n",
              " 'd',\n",
              " 'e',\n",
              " 'f',\n",
              " 'g',\n",
              " 'h',\n",
              " 'i',\n",
              " 'j',\n",
              " 'k',\n",
              " 'l',\n",
              " 'm',\n",
              " 'n',\n",
              " 'o',\n",
              " 'p',\n",
              " 'q',\n",
              " 'r',\n",
              " 's',\n",
              " 't',\n",
              " 'u',\n",
              " 'v',\n",
              " 'w',\n",
              " 'x',\n",
              " 'y',\n",
              " 'z']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Nm9TWmtn4cr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "b19e7b37-9eee-4445-a6c5-776ef8b9a447"
      },
      "source": [
        "# create mapping of unique chars to integers\n",
        "\n",
        "chars = sorted(list (set (' '.join(list_of_sentences_updated))))\n",
        "char_to_int = dict((c, i) for i, c in enumerate(chars))\n",
        "print(char_to_int)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{' ': 0, '0': 1, '3': 2, 'a': 3, 'b': 4, 'c': 5, 'd': 6, 'e': 7, 'f': 8, 'g': 9, 'h': 10, 'i': 11, 'j': 12, 'k': 13, 'l': 14, 'm': 15, 'n': 16, 'o': 17, 'p': 18, 'q': 19, 'r': 20, 's': 21, 't': 22, 'u': 23, 'v': 24, 'w': 25, 'x': 26, 'y': 27, 'z': 28}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dvjCZStLoGjg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "ed79491f-4527-49e3-e9fe-57f9fd8cd3d7"
      },
      "source": [
        "n_chars = len(raw_text)\n",
        "n_vocab = len(chars)\n",
        "print (\"Total Characters: \", n_chars)\n",
        "print (\"Total Vocab: \", n_vocab)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total Characters:  136087\n",
            "Total Vocab:  29\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kIJJH2RloP0o",
        "colab_type": "text"
      },
      "source": [
        "### Convert the text of sentences in to numbers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rjInoPnUoNMd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#find the length of each sentence\n",
        "list_of_sentences_updated_numbers = []\n",
        "for sentence in list_of_sentences_updated:\n",
        "#   print(len(sentence))\n",
        "  char_to_listofnumbers = [char_to_int[char] for char in sentence]\n",
        "  list_of_sentences_updated_numbers.append (char_to_listofnumbers )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LamTUC_roblY",
        "colab_type": "text"
      },
      "source": [
        "## Creating padded sequences for list_of_sentences_updated"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UsWFG3sJoT_U",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "4820a0fe-5cac-4df5-ccb8-a69e99ab9204"
      },
      "source": [
        "from keras.preprocessing.sequence import pad_sequences\n",
        "# define sequences\n",
        "sequences = list_of_sentences_updated_numbers\n",
        "# pad sequence\n",
        "padded = pad_sequences(sequences)\n",
        "print(padded)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[ 0  0  0 ...  3 16  6]\n",
            " [ 0  0  0 ... 17 14 14]\n",
            " [ 0  0  0 ...  0  2  1]\n",
            " ...\n",
            " [ 0  0  0 ... 11 22 10]\n",
            " [ 0  0  0 ... 17 27 21]\n",
            " [ 0  0  0 ...  3 27 21]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gq7vibMkoerb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 867
        },
        "outputId": "ad3d418a-b1e8-42f0-ce7d-6eddbb03ee2c"
      },
      "source": [
        "for i in padded[0:50]:\n",
        "  print(len(i) , i [-1])"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "73 6\n",
            "73 14\n",
            "73 1\n",
            "73 7\n",
            "73 7\n",
            "73 7\n",
            "73 16\n",
            "73 20\n",
            "73 21\n",
            "73 7\n",
            "73 7\n",
            "73 6\n",
            "73 16\n",
            "73 20\n",
            "73 17\n",
            "73 20\n",
            "73 22\n",
            "73 7\n",
            "73 10\n",
            "73 16\n",
            "73 6\n",
            "73 10\n",
            "73 6\n",
            "73 7\n",
            "73 7\n",
            "73 25\n",
            "73 16\n",
            "73 16\n",
            "73 13\n",
            "73 18\n",
            "73 14\n",
            "73 6\n",
            "73 21\n",
            "73 22\n",
            "73 7\n",
            "73 10\n",
            "73 21\n",
            "73 21\n",
            "73 22\n",
            "73 20\n",
            "73 21\n",
            "73 22\n",
            "73 14\n",
            "73 22\n",
            "73 18\n",
            "73 7\n",
            "73 25\n",
            "73 9\n",
            "73 20\n",
            "73 14\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KeV_EoEhoiNX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "684958b4-bd4b-4cff-839c-a0886887497e"
      },
      "source": [
        "# prepare the dataset of input to output pairs encoded as integers\n",
        "dataX = []\n",
        "dataY = []\n",
        "\n",
        "for sentence in padded:\n",
        "  train_input = sentence[0: -1]\n",
        "  train_output = sentence[-1] \n",
        "  dataX.append(train_input)\n",
        "  dataY.append(train_output)\n",
        "n_patterns = len(dataX)\n",
        "print (\"Total Patterns: \", n_patterns)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total Patterns:  2480\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a-t3ExyRopH0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "64a373c8-6a22-4324-e45e-99cb0931f39e"
      },
      "source": [
        "print(len(dataX),len(dataY) )\n",
        "print (len(dataX[0]), dataX[0], dataY[0] )\n",
        "print(len(dataX[1]), dataX[1], dataY[1])"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2480 2480\n",
            "72 [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  3 14 11  5  7 21\n",
            "  0  3  6 24  7 16 22 23 20  7 21  0 11 16  0 25 17 16  6  7 20 14  3 16] 6\n",
            "72 [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "  0  0  0  0  0  0  0  0  0  0  0  0 14  7 25 11 21  0  5  3 20 20 17 14] 14\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qn8Rgx9TosMP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# reshape X to be [samples, time steps, features]\n",
        "X = numpy.reshape(dataX, (n_patterns, len(dataX[0]), 1))\n",
        "# normalize\n",
        "X = X / float(n_vocab)\n",
        "# one hot encode the output variable\n",
        "y = np_utils.to_categorical(dataY)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wS8JHIhuoz6D",
        "colab_type": "text"
      },
      "source": [
        "### Add dropout to the input layer and remove dropout  before Dense"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oXdqQZL4oxQj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 309
        },
        "outputId": "b65145cb-2ee1-4abb-93f0-197c4aed5efc"
      },
      "source": [
        "model = Sequential()\n",
        "model.add(LSTM(256, input_shape=(X.shape[1], X.shape[2]), return_sequences=True, dropout = 0.1))\n",
        "model.add(Dropout(0.1))\n",
        "model.add(LSTM(256))\n",
        "model.add(Dense(y.shape[1], activation='softmax'))\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam')"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W0725 14:57:57.995127 139697040070528 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "W0725 14:57:58.046234 139697040070528 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "W0725 14:57:58.054367 139697040070528 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "W0725 14:57:58.250471 139697040070528 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:133: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
            "\n",
            "W0725 14:57:58.261350 139697040070528 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "W0725 14:57:58.821577 139697040070528 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "W0725 14:57:58.844368 139697040070528 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3295: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ynqd63_Do39E",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "414a3b24-db39-49d2-e747-385d7429ae15"
      },
      "source": [
        "# define the checkpoint\n",
        "filepath=\"2_weights-improvement-{epoch:02d}-{loss:.4f}-bigger.hdf5\"\n",
        "checkpoint = ModelCheckpoint(filepath, monitor='loss', verbose=1, save_best_only=True, mode='min')\n",
        "callbacks_list = [checkpoint]\n",
        "# fit the model\n",
        "model.fit(X, y, epochs=100, batch_size=64, callbacks=callbacks_list)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "W0725 14:58:27.972914 139697040070528 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "2480/2480 [==============================] - 12s 5ms/step - loss: 2.6994\n",
            "\n",
            "Epoch 00001: loss improved from inf to 2.69941, saving model to 2_weights-improvement-01-2.6994-bigger.hdf5\n",
            "Epoch 2/100\n",
            "2480/2480 [==============================] - 8s 3ms/step - loss: 2.5756\n",
            "\n",
            "Epoch 00002: loss improved from 2.69941 to 2.57557, saving model to 2_weights-improvement-02-2.5756-bigger.hdf5\n",
            "Epoch 3/100\n",
            "2480/2480 [==============================] - 8s 3ms/step - loss: 2.5788\n",
            "\n",
            "Epoch 00003: loss did not improve from 2.57557\n",
            "Epoch 4/100\n",
            "2480/2480 [==============================] - 8s 3ms/step - loss: 2.5705\n",
            "\n",
            "Epoch 00004: loss improved from 2.57557 to 2.57047, saving model to 2_weights-improvement-04-2.5705-bigger.hdf5\n",
            "Epoch 5/100\n",
            "2480/2480 [==============================] - 8s 3ms/step - loss: 2.5750\n",
            "\n",
            "Epoch 00005: loss did not improve from 2.57047\n",
            "Epoch 6/100\n",
            "2480/2480 [==============================] - 8s 3ms/step - loss: 2.5643\n",
            "\n",
            "Epoch 00006: loss improved from 2.57047 to 2.56431, saving model to 2_weights-improvement-06-2.5643-bigger.hdf5\n",
            "Epoch 7/100\n",
            "2480/2480 [==============================] - 8s 3ms/step - loss: 2.5632\n",
            "\n",
            "Epoch 00007: loss improved from 2.56431 to 2.56321, saving model to 2_weights-improvement-07-2.5632-bigger.hdf5\n",
            "Epoch 8/100\n",
            "2480/2480 [==============================] - 8s 3ms/step - loss: 2.5587\n",
            "\n",
            "Epoch 00008: loss improved from 2.56321 to 2.55870, saving model to 2_weights-improvement-08-2.5587-bigger.hdf5\n",
            "Epoch 9/100\n",
            "2480/2480 [==============================] - 8s 3ms/step - loss: 2.5535\n",
            "\n",
            "Epoch 00009: loss improved from 2.55870 to 2.55353, saving model to 2_weights-improvement-09-2.5535-bigger.hdf5\n",
            "Epoch 10/100\n",
            "2480/2480 [==============================] - 8s 3ms/step - loss: 2.5378\n",
            "\n",
            "Epoch 00010: loss improved from 2.55353 to 2.53777, saving model to 2_weights-improvement-10-2.5378-bigger.hdf5\n",
            "Epoch 11/100\n",
            "2480/2480 [==============================] - 8s 3ms/step - loss: 2.5356\n",
            "\n",
            "Epoch 00011: loss improved from 2.53777 to 2.53555, saving model to 2_weights-improvement-11-2.5356-bigger.hdf5\n",
            "Epoch 12/100\n",
            "2480/2480 [==============================] - 8s 3ms/step - loss: 2.5218\n",
            "\n",
            "Epoch 00012: loss improved from 2.53555 to 2.52177, saving model to 2_weights-improvement-12-2.5218-bigger.hdf5\n",
            "Epoch 13/100\n",
            "2480/2480 [==============================] - 8s 3ms/step - loss: 2.4994\n",
            "\n",
            "Epoch 00013: loss improved from 2.52177 to 2.49937, saving model to 2_weights-improvement-13-2.4994-bigger.hdf5\n",
            "Epoch 14/100\n",
            "2480/2480 [==============================] - 8s 3ms/step - loss: 2.4763\n",
            "\n",
            "Epoch 00014: loss improved from 2.49937 to 2.47628, saving model to 2_weights-improvement-14-2.4763-bigger.hdf5\n",
            "Epoch 15/100\n",
            "2480/2480 [==============================] - 8s 3ms/step - loss: 2.4263\n",
            "\n",
            "Epoch 00015: loss improved from 2.47628 to 2.42631, saving model to 2_weights-improvement-15-2.4263-bigger.hdf5\n",
            "Epoch 16/100\n",
            "2480/2480 [==============================] - 8s 3ms/step - loss: 2.3709\n",
            "\n",
            "Epoch 00016: loss improved from 2.42631 to 2.37087, saving model to 2_weights-improvement-16-2.3709-bigger.hdf5\n",
            "Epoch 17/100\n",
            "2480/2480 [==============================] - 8s 3ms/step - loss: 2.3186\n",
            "\n",
            "Epoch 00017: loss improved from 2.37087 to 2.31855, saving model to 2_weights-improvement-17-2.3186-bigger.hdf5\n",
            "Epoch 18/100\n",
            "2480/2480 [==============================] - 8s 3ms/step - loss: 2.2659\n",
            "\n",
            "Epoch 00018: loss improved from 2.31855 to 2.26591, saving model to 2_weights-improvement-18-2.2659-bigger.hdf5\n",
            "Epoch 19/100\n",
            "2480/2480 [==============================] - 8s 3ms/step - loss: 2.2077\n",
            "\n",
            "Epoch 00019: loss improved from 2.26591 to 2.20773, saving model to 2_weights-improvement-19-2.2077-bigger.hdf5\n",
            "Epoch 20/100\n",
            "2480/2480 [==============================] - 8s 3ms/step - loss: 2.1327\n",
            "\n",
            "Epoch 00020: loss improved from 2.20773 to 2.13274, saving model to 2_weights-improvement-20-2.1327-bigger.hdf5\n",
            "Epoch 21/100\n",
            "2480/2480 [==============================] - 8s 3ms/step - loss: 2.0617\n",
            "\n",
            "Epoch 00021: loss improved from 2.13274 to 2.06168, saving model to 2_weights-improvement-21-2.0617-bigger.hdf5\n",
            "Epoch 22/100\n",
            "2480/2480 [==============================] - 8s 3ms/step - loss: 1.9791\n",
            "\n",
            "Epoch 00022: loss improved from 2.06168 to 1.97911, saving model to 2_weights-improvement-22-1.9791-bigger.hdf5\n",
            "Epoch 23/100\n",
            "2480/2480 [==============================] - 8s 3ms/step - loss: 1.9042\n",
            "\n",
            "Epoch 00023: loss improved from 1.97911 to 1.90417, saving model to 2_weights-improvement-23-1.9042-bigger.hdf5\n",
            "Epoch 24/100\n",
            "2480/2480 [==============================] - 8s 3ms/step - loss: 1.8491\n",
            "\n",
            "Epoch 00024: loss improved from 1.90417 to 1.84911, saving model to 2_weights-improvement-24-1.8491-bigger.hdf5\n",
            "Epoch 25/100\n",
            "2480/2480 [==============================] - 8s 3ms/step - loss: 1.7691\n",
            "\n",
            "Epoch 00025: loss improved from 1.84911 to 1.76905, saving model to 2_weights-improvement-25-1.7691-bigger.hdf5\n",
            "Epoch 26/100\n",
            "2480/2480 [==============================] - 8s 3ms/step - loss: 1.7390\n",
            "\n",
            "Epoch 00026: loss improved from 1.76905 to 1.73900, saving model to 2_weights-improvement-26-1.7390-bigger.hdf5\n",
            "Epoch 27/100\n",
            "2480/2480 [==============================] - 8s 3ms/step - loss: 1.6641\n",
            "\n",
            "Epoch 00027: loss improved from 1.73900 to 1.66407, saving model to 2_weights-improvement-27-1.6641-bigger.hdf5\n",
            "Epoch 28/100\n",
            "2480/2480 [==============================] - 8s 3ms/step - loss: 1.5847\n",
            "\n",
            "Epoch 00028: loss improved from 1.66407 to 1.58470, saving model to 2_weights-improvement-28-1.5847-bigger.hdf5\n",
            "Epoch 29/100\n",
            "2480/2480 [==============================] - 8s 3ms/step - loss: 1.5472\n",
            "\n",
            "Epoch 00029: loss improved from 1.58470 to 1.54719, saving model to 2_weights-improvement-29-1.5472-bigger.hdf5\n",
            "Epoch 30/100\n",
            "2480/2480 [==============================] - 8s 3ms/step - loss: 1.5089\n",
            "\n",
            "Epoch 00030: loss improved from 1.54719 to 1.50895, saving model to 2_weights-improvement-30-1.5089-bigger.hdf5\n",
            "Epoch 31/100\n",
            "2480/2480 [==============================] - 8s 3ms/step - loss: 1.4510\n",
            "\n",
            "Epoch 00031: loss improved from 1.50895 to 1.45096, saving model to 2_weights-improvement-31-1.4510-bigger.hdf5\n",
            "Epoch 32/100\n",
            "2480/2480 [==============================] - 8s 3ms/step - loss: 1.3892\n",
            "\n",
            "Epoch 00032: loss improved from 1.45096 to 1.38924, saving model to 2_weights-improvement-32-1.3892-bigger.hdf5\n",
            "Epoch 33/100\n",
            "2480/2480 [==============================] - 8s 3ms/step - loss: 1.3376\n",
            "\n",
            "Epoch 00033: loss improved from 1.38924 to 1.33757, saving model to 2_weights-improvement-33-1.3376-bigger.hdf5\n",
            "Epoch 34/100\n",
            "2480/2480 [==============================] - 8s 3ms/step - loss: 1.3110\n",
            "\n",
            "Epoch 00034: loss improved from 1.33757 to 1.31103, saving model to 2_weights-improvement-34-1.3110-bigger.hdf5\n",
            "Epoch 35/100\n",
            "2480/2480 [==============================] - 8s 3ms/step - loss: 1.2246\n",
            "\n",
            "Epoch 00035: loss improved from 1.31103 to 1.22459, saving model to 2_weights-improvement-35-1.2246-bigger.hdf5\n",
            "Epoch 36/100\n",
            "2480/2480 [==============================] - 8s 3ms/step - loss: 1.1587\n",
            "\n",
            "Epoch 00036: loss improved from 1.22459 to 1.15871, saving model to 2_weights-improvement-36-1.1587-bigger.hdf5\n",
            "Epoch 37/100\n",
            "2480/2480 [==============================] - 8s 3ms/step - loss: 1.0932\n",
            "\n",
            "Epoch 00037: loss improved from 1.15871 to 1.09317, saving model to 2_weights-improvement-37-1.0932-bigger.hdf5\n",
            "Epoch 38/100\n",
            "2480/2480 [==============================] - 8s 3ms/step - loss: 1.0448\n",
            "\n",
            "Epoch 00038: loss improved from 1.09317 to 1.04484, saving model to 2_weights-improvement-38-1.0448-bigger.hdf5\n",
            "Epoch 39/100\n",
            "2480/2480 [==============================] - 8s 3ms/step - loss: 0.9678\n",
            "\n",
            "Epoch 00039: loss improved from 1.04484 to 0.96781, saving model to 2_weights-improvement-39-0.9678-bigger.hdf5\n",
            "Epoch 40/100\n",
            "2480/2480 [==============================] - 8s 3ms/step - loss: 0.9289\n",
            "\n",
            "Epoch 00040: loss improved from 0.96781 to 0.92889, saving model to 2_weights-improvement-40-0.9289-bigger.hdf5\n",
            "Epoch 41/100\n",
            "2480/2480 [==============================] - 8s 3ms/step - loss: 0.8954\n",
            "\n",
            "Epoch 00041: loss improved from 0.92889 to 0.89539, saving model to 2_weights-improvement-41-0.8954-bigger.hdf5\n",
            "Epoch 42/100\n",
            "2480/2480 [==============================] - 8s 3ms/step - loss: 0.8351\n",
            "\n",
            "Epoch 00042: loss improved from 0.89539 to 0.83508, saving model to 2_weights-improvement-42-0.8351-bigger.hdf5\n",
            "Epoch 43/100\n",
            "2480/2480 [==============================] - 8s 3ms/step - loss: 0.8107\n",
            "\n",
            "Epoch 00043: loss improved from 0.83508 to 0.81067, saving model to 2_weights-improvement-43-0.8107-bigger.hdf5\n",
            "Epoch 44/100\n",
            "2480/2480 [==============================] - 8s 3ms/step - loss: 0.7416\n",
            "\n",
            "Epoch 00044: loss improved from 0.81067 to 0.74158, saving model to 2_weights-improvement-44-0.7416-bigger.hdf5\n",
            "Epoch 45/100\n",
            "2480/2480 [==============================] - 8s 3ms/step - loss: 0.6847\n",
            "\n",
            "Epoch 00045: loss improved from 0.74158 to 0.68472, saving model to 2_weights-improvement-45-0.6847-bigger.hdf5\n",
            "Epoch 46/100\n",
            "2480/2480 [==============================] - 8s 3ms/step - loss: 0.6418\n",
            "\n",
            "Epoch 00046: loss improved from 0.68472 to 0.64183, saving model to 2_weights-improvement-46-0.6418-bigger.hdf5\n",
            "Epoch 47/100\n",
            "2480/2480 [==============================] - 8s 3ms/step - loss: 0.6069\n",
            "\n",
            "Epoch 00047: loss improved from 0.64183 to 0.60691, saving model to 2_weights-improvement-47-0.6069-bigger.hdf5\n",
            "Epoch 48/100\n",
            "2480/2480 [==============================] - 8s 3ms/step - loss: 0.5326\n",
            "\n",
            "Epoch 00048: loss improved from 0.60691 to 0.53256, saving model to 2_weights-improvement-48-0.5326-bigger.hdf5\n",
            "Epoch 49/100\n",
            "2480/2480 [==============================] - 8s 3ms/step - loss: 0.5116\n",
            "\n",
            "Epoch 00049: loss improved from 0.53256 to 0.51162, saving model to 2_weights-improvement-49-0.5116-bigger.hdf5\n",
            "Epoch 50/100\n",
            "2480/2480 [==============================] - 8s 3ms/step - loss: 0.4927\n",
            "\n",
            "Epoch 00050: loss improved from 0.51162 to 0.49266, saving model to 2_weights-improvement-50-0.4927-bigger.hdf5\n",
            "Epoch 51/100\n",
            "2480/2480 [==============================] - 8s 3ms/step - loss: 0.4758\n",
            "\n",
            "Epoch 00051: loss improved from 0.49266 to 0.47576, saving model to 2_weights-improvement-51-0.4758-bigger.hdf5\n",
            "Epoch 52/100\n",
            "2480/2480 [==============================] - 8s 3ms/step - loss: 0.4331\n",
            "\n",
            "Epoch 00052: loss improved from 0.47576 to 0.43306, saving model to 2_weights-improvement-52-0.4331-bigger.hdf5\n",
            "Epoch 53/100\n",
            "2480/2480 [==============================] - 8s 3ms/step - loss: 0.3942\n",
            "\n",
            "Epoch 00053: loss improved from 0.43306 to 0.39417, saving model to 2_weights-improvement-53-0.3942-bigger.hdf5\n",
            "Epoch 54/100\n",
            "2480/2480 [==============================] - 8s 3ms/step - loss: 0.3903\n",
            "\n",
            "Epoch 00054: loss improved from 0.39417 to 0.39031, saving model to 2_weights-improvement-54-0.3903-bigger.hdf5\n",
            "Epoch 55/100\n",
            "2480/2480 [==============================] - 8s 3ms/step - loss: 0.3812\n",
            "\n",
            "Epoch 00055: loss improved from 0.39031 to 0.38125, saving model to 2_weights-improvement-55-0.3812-bigger.hdf5\n",
            "Epoch 56/100\n",
            "2480/2480 [==============================] - 8s 3ms/step - loss: 0.3428\n",
            "\n",
            "Epoch 00056: loss improved from 0.38125 to 0.34283, saving model to 2_weights-improvement-56-0.3428-bigger.hdf5\n",
            "Epoch 57/100\n",
            "2480/2480 [==============================] - 8s 3ms/step - loss: 0.3286\n",
            "\n",
            "Epoch 00057: loss improved from 0.34283 to 0.32864, saving model to 2_weights-improvement-57-0.3286-bigger.hdf5\n",
            "Epoch 58/100\n",
            "2480/2480 [==============================] - 8s 3ms/step - loss: 0.3333\n",
            "\n",
            "Epoch 00058: loss did not improve from 0.32864\n",
            "Epoch 59/100\n",
            "2480/2480 [==============================] - 8s 3ms/step - loss: 0.3477\n",
            "\n",
            "Epoch 00059: loss did not improve from 0.32864\n",
            "Epoch 60/100\n",
            "2480/2480 [==============================] - 8s 3ms/step - loss: 0.3509\n",
            "\n",
            "Epoch 00060: loss did not improve from 0.32864\n",
            "Epoch 61/100\n",
            "2480/2480 [==============================] - 7s 3ms/step - loss: 0.3251\n",
            "\n",
            "Epoch 00061: loss improved from 0.32864 to 0.32506, saving model to 2_weights-improvement-61-0.3251-bigger.hdf5\n",
            "Epoch 62/100\n",
            "2480/2480 [==============================] - 8s 3ms/step - loss: 0.3167\n",
            "\n",
            "Epoch 00062: loss improved from 0.32506 to 0.31670, saving model to 2_weights-improvement-62-0.3167-bigger.hdf5\n",
            "Epoch 63/100\n",
            "2480/2480 [==============================] - 8s 3ms/step - loss: 0.2985\n",
            "\n",
            "Epoch 00063: loss improved from 0.31670 to 0.29847, saving model to 2_weights-improvement-63-0.2985-bigger.hdf5\n",
            "Epoch 64/100\n",
            "2480/2480 [==============================] - 8s 3ms/step - loss: 0.3110\n",
            "\n",
            "Epoch 00064: loss did not improve from 0.29847\n",
            "Epoch 65/100\n",
            "2480/2480 [==============================] - 8s 3ms/step - loss: 0.3040\n",
            "\n",
            "Epoch 00065: loss did not improve from 0.29847\n",
            "Epoch 66/100\n",
            "2480/2480 [==============================] - 8s 3ms/step - loss: 0.2722\n",
            "\n",
            "Epoch 00066: loss improved from 0.29847 to 0.27218, saving model to 2_weights-improvement-66-0.2722-bigger.hdf5\n",
            "Epoch 67/100\n",
            "2480/2480 [==============================] - 7s 3ms/step - loss: 0.3043\n",
            "\n",
            "Epoch 00067: loss did not improve from 0.27218\n",
            "Epoch 68/100\n",
            "2480/2480 [==============================] - 7s 3ms/step - loss: 0.2970\n",
            "\n",
            "Epoch 00068: loss did not improve from 0.27218\n",
            "Epoch 69/100\n",
            "2480/2480 [==============================] - 7s 3ms/step - loss: 0.3020\n",
            "\n",
            "Epoch 00069: loss did not improve from 0.27218\n",
            "Epoch 70/100\n",
            "2480/2480 [==============================] - 7s 3ms/step - loss: 0.2668\n",
            "\n",
            "Epoch 00070: loss improved from 0.27218 to 0.26676, saving model to 2_weights-improvement-70-0.2668-bigger.hdf5\n",
            "Epoch 71/100\n",
            "2480/2480 [==============================] - 7s 3ms/step - loss: 0.3044\n",
            "\n",
            "Epoch 00071: loss did not improve from 0.26676\n",
            "Epoch 72/100\n",
            "2480/2480 [==============================] - 8s 3ms/step - loss: 0.2806\n",
            "\n",
            "Epoch 00072: loss did not improve from 0.26676\n",
            "Epoch 73/100\n",
            "2480/2480 [==============================] - 8s 3ms/step - loss: 0.2643\n",
            "\n",
            "Epoch 00073: loss improved from 0.26676 to 0.26427, saving model to 2_weights-improvement-73-0.2643-bigger.hdf5\n",
            "Epoch 74/100\n",
            "2480/2480 [==============================] - 7s 3ms/step - loss: 0.2772\n",
            "\n",
            "Epoch 00074: loss did not improve from 0.26427\n",
            "Epoch 75/100\n",
            "2480/2480 [==============================] - 7s 3ms/step - loss: 0.2667\n",
            "\n",
            "Epoch 00075: loss did not improve from 0.26427\n",
            "Epoch 76/100\n",
            "2480/2480 [==============================] - 7s 3ms/step - loss: 0.2579\n",
            "\n",
            "Epoch 00076: loss improved from 0.26427 to 0.25792, saving model to 2_weights-improvement-76-0.2579-bigger.hdf5\n",
            "Epoch 77/100\n",
            "2480/2480 [==============================] - 7s 3ms/step - loss: 0.2909\n",
            "\n",
            "Epoch 00077: loss did not improve from 0.25792\n",
            "Epoch 78/100\n",
            "2480/2480 [==============================] - 7s 3ms/step - loss: 0.2616\n",
            "\n",
            "Epoch 00078: loss did not improve from 0.25792\n",
            "Epoch 79/100\n",
            "2480/2480 [==============================] - 7s 3ms/step - loss: 0.2542\n",
            "\n",
            "Epoch 00079: loss improved from 0.25792 to 0.25416, saving model to 2_weights-improvement-79-0.2542-bigger.hdf5\n",
            "Epoch 80/100\n",
            "2480/2480 [==============================] - 7s 3ms/step - loss: 0.2515\n",
            "\n",
            "Epoch 00080: loss improved from 0.25416 to 0.25152, saving model to 2_weights-improvement-80-0.2515-bigger.hdf5\n",
            "Epoch 81/100\n",
            "2480/2480 [==============================] - 8s 3ms/step - loss: 0.2832\n",
            "\n",
            "Epoch 00081: loss did not improve from 0.25152\n",
            "Epoch 82/100\n",
            "2480/2480 [==============================] - 7s 3ms/step - loss: 0.2845\n",
            "\n",
            "Epoch 00082: loss did not improve from 0.25152\n",
            "Epoch 83/100\n",
            "2480/2480 [==============================] - 8s 3ms/step - loss: 0.2618\n",
            "\n",
            "Epoch 00083: loss did not improve from 0.25152\n",
            "Epoch 84/100\n",
            "2480/2480 [==============================] - 7s 3ms/step - loss: 0.3009\n",
            "\n",
            "Epoch 00084: loss did not improve from 0.25152\n",
            "Epoch 85/100\n",
            "2480/2480 [==============================] - 7s 3ms/step - loss: 0.2479\n",
            "\n",
            "Epoch 00085: loss improved from 0.25152 to 0.24790, saving model to 2_weights-improvement-85-0.2479-bigger.hdf5\n",
            "Epoch 86/100\n",
            "2480/2480 [==============================] - 7s 3ms/step - loss: 0.2597\n",
            "\n",
            "Epoch 00086: loss did not improve from 0.24790\n",
            "Epoch 87/100\n",
            "2480/2480 [==============================] - 7s 3ms/step - loss: 0.2835\n",
            "\n",
            "Epoch 00087: loss did not improve from 0.24790\n",
            "Epoch 88/100\n",
            "2480/2480 [==============================] - 7s 3ms/step - loss: 0.2419\n",
            "\n",
            "Epoch 00088: loss improved from 0.24790 to 0.24188, saving model to 2_weights-improvement-88-0.2419-bigger.hdf5\n",
            "Epoch 89/100\n",
            "2480/2480 [==============================] - 8s 3ms/step - loss: 0.2543\n",
            "\n",
            "Epoch 00089: loss did not improve from 0.24188\n",
            "Epoch 90/100\n",
            "2480/2480 [==============================] - 8s 3ms/step - loss: 0.2320\n",
            "\n",
            "Epoch 00090: loss improved from 0.24188 to 0.23199, saving model to 2_weights-improvement-90-0.2320-bigger.hdf5\n",
            "Epoch 91/100\n",
            "2480/2480 [==============================] - 7s 3ms/step - loss: 0.2472\n",
            "\n",
            "Epoch 00091: loss did not improve from 0.23199\n",
            "Epoch 92/100\n",
            "2480/2480 [==============================] - 7s 3ms/step - loss: 0.2726\n",
            "\n",
            "Epoch 00092: loss did not improve from 0.23199\n",
            "Epoch 93/100\n",
            "2480/2480 [==============================] - 7s 3ms/step - loss: 0.2208\n",
            "\n",
            "Epoch 00093: loss improved from 0.23199 to 0.22083, saving model to 2_weights-improvement-93-0.2208-bigger.hdf5\n",
            "Epoch 94/100\n",
            "2480/2480 [==============================] - 8s 3ms/step - loss: 0.2242\n",
            "\n",
            "Epoch 00094: loss did not improve from 0.22083\n",
            "Epoch 95/100\n",
            "2480/2480 [==============================] - 7s 3ms/step - loss: 0.2308\n",
            "\n",
            "Epoch 00095: loss did not improve from 0.22083\n",
            "Epoch 96/100\n",
            "2480/2480 [==============================] - 7s 3ms/step - loss: 0.2338\n",
            "\n",
            "Epoch 00096: loss did not improve from 0.22083\n",
            "Epoch 97/100\n",
            "2480/2480 [==============================] - 7s 3ms/step - loss: 0.2160\n",
            "\n",
            "Epoch 00097: loss improved from 0.22083 to 0.21603, saving model to 2_weights-improvement-97-0.2160-bigger.hdf5\n",
            "Epoch 98/100\n",
            "2480/2480 [==============================] - 8s 3ms/step - loss: 0.2013\n",
            "\n",
            "Epoch 00098: loss improved from 0.21603 to 0.20133, saving model to 2_weights-improvement-98-0.2013-bigger.hdf5\n",
            "Epoch 99/100\n",
            "2480/2480 [==============================] - 8s 3ms/step - loss: 0.2240\n",
            "\n",
            "Epoch 00099: loss did not improve from 0.20133\n",
            "Epoch 100/100\n",
            "2480/2480 [==============================] - 7s 3ms/step - loss: 0.2160\n",
            "\n",
            "Epoch 00100: loss did not improve from 0.20133\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f0d758e6da0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aMpYS-Qlo_Pv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# load the network weights\n",
        "filename = \"2_weights-improvement-98-0.2013-bigger.hdf5\"\n",
        "model.load_weights(filename)\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gvuCzYfqtPZv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 510
        },
        "outputId": "ba5e3628-589f-44c0-f1f9-dbfd173016c9"
      },
      "source": [
        "int_to_char = dict((i, c) for i, c in enumerate(chars))\n",
        "int_to_char"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{0: ' ',\n",
              " 1: '0',\n",
              " 2: '3',\n",
              " 3: 'a',\n",
              " 4: 'b',\n",
              " 5: 'c',\n",
              " 6: 'd',\n",
              " 7: 'e',\n",
              " 8: 'f',\n",
              " 9: 'g',\n",
              " 10: 'h',\n",
              " 11: 'i',\n",
              " 12: 'j',\n",
              " 13: 'k',\n",
              " 14: 'l',\n",
              " 15: 'm',\n",
              " 16: 'n',\n",
              " 17: 'o',\n",
              " 18: 'p',\n",
              " 19: 'q',\n",
              " 20: 'r',\n",
              " 21: 's',\n",
              " 22: 't',\n",
              " 23: 'u',\n",
              " 24: 'v',\n",
              " 25: 'w',\n",
              " 26: 'x',\n",
              " 27: 'y',\n",
              " 28: 'z'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nBw4dmvjvhlj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "outputId": "6744cc55-9c0f-43a3-ee57-668b17b9caca"
      },
      "source": [
        "import sys\n",
        "# pick a random seed\n",
        "start = numpy.random.randint(0, len(dataX)-1)\n",
        "pattern = list(dataX[start])\n",
        "print (\"Seed:\",start )\n",
        "print (\"\\\"\", ''.join([int_to_char[value] for value in pattern]), \"\\\"\")\n",
        "# generate characters\n",
        "for i in range(500):\n",
        "\tx = numpy.reshape(pattern, (1, len(pattern), 1))\n",
        "\tx = x / float(n_vocab)\n",
        "\tprediction = model.predict(x, verbose=0)\n",
        "\tindex = numpy.argmax(prediction)\n",
        "\tresult = int_to_char[index]\n",
        "# \tseq_in = [int_to_char[value] for value in pattern]\n",
        "\tprint(result, end = '')\n",
        "\tpattern.append(index)\n",
        "\tpattern = pattern[1:len(pattern)]\n",
        "print (\"\\nDone.\")"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Seed: 1768\n",
            "\"       as they walked off together alice heard the king say in a low voic \"\n",
            "esestytestesryyyyesnesryyyyesneskyyyyssnnngddaatdssssessyyessedrdatouressgsyyyedrnngddaatdsserngrnyyesneseaaaannngeddiredtedmysyhsnerndinryyesnesesytyysessyydsnyyyyedrrdaatosessesssyedredtssndssnyesyyyedrrwddrowmdssurdssyyedrrwtessyyysessyyyyessnyyyyyesneskyyyyynsnngddysyyessgsyyyysnnngddddtsssesscrryyyyessesyyyyyesnngdrdatesysmsneddaatsreddmdrdrtttessesryyyyedrnggrsyyynsndsnyyyyesneskyyyyynsnngddystyessestyyyssnnngddaatxttessedrsyyymsnnngyyyyysesnyyyyesneskyyyyyessgyyyyysesngddtttyytesngsgdddys\n",
            "Done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LRVr8LYoxwLn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "outputId": "9e0babf9-05e9-4db8-e3cb-69ab408389ac"
      },
      "source": [
        "import sys\n",
        "# pick a random seed\n",
        "start = numpy.random.randint(0, len(dataX)-1)\n",
        "pattern = list(dataX[start])\n",
        "print (\"Seed:\",start )\n",
        "print (\"\\\"\", ''.join([int_to_char[value] for value in pattern]), \"\\\"\")\n",
        "# generate characters\n",
        "for i in range(500):\n",
        "\tx = numpy.reshape(pattern, (1, len(pattern), 1))\n",
        "\tx = x / float(n_vocab)\n",
        "\tprediction = model.predict(x, verbose=0)\n",
        "\tindex = numpy.argmax(prediction)\n",
        "\tresult = int_to_char[index]\n",
        "# \tseq_in = [int_to_char[value] for value in pattern]\n",
        "\tprint(result, end = '')\n",
        "\tpattern.append(index)\n",
        "\tpattern = pattern[1:len(pattern)]\n",
        "print (\"\\nDone.\")"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Seed: 2125\n",
            "\"                                                               was talkin \"\n",
            "gdddssernesesnernesndsnnndsnnresnnddreanysndddnnedaaodensssessnyyyyyyyessuuynsnesgdrytyysesngsyyyyyessnyndddatttessgsyyyessesrytdstgdrsyyyssnnngddaatdssssessyyessedrdatourdssgsryyedrnngddaatssdssessnyyyyndsngskyyyyesneskyyyyynsnngddystyessesryyyssnnngddaatxttesserryyyyessgsyyyyyessnynyyyesngskdrytyysesnngddaattrdddmttteddtttyyyesfdsstyyyesseskyyyyyessgsyyyysesngskyyyynsnngdddtsttessgsyyyysesngstyyyynsnnngdddtsttessgdrsyyesnnsgsgdrtuyessnsndddaatxtdddtttteddtttyyyyyessyyypesgdrstyysesngskddddtttm\n",
            "Done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "68cSu2okw3GY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "outputId": "684e427f-d46c-4ffd-d643-013055ab5f85"
      },
      "source": [
        "import sys\n",
        "# pick a random seed\n",
        "start = numpy.random.randint(0, len(dataX)-1)\n",
        "pattern = list(dataX[start])\n",
        "print (\"Seed:\",start )\n",
        "print (\"\\\"\", ''.join([int_to_char[value] for value in pattern]), \"\\\"\")\n",
        "# generate characters\n",
        "for i in range(500):\n",
        "\tx = numpy.reshape(pattern, (1, len(pattern), 1))\n",
        "\tx = x / float(n_vocab)\n",
        "\tprediction = model.predict(x, verbose=0)\n",
        "\tindex = numpy.argmax(prediction)\n",
        "\tresult = int_to_char[index]\n",
        "# \tseq_in = [int_to_char[value] for value in pattern]\n",
        "\tprint(result, end = '')\n",
        "\tpattern.append(index)\n",
        "\tpattern = pattern[1:len(pattern)]\n",
        "print (\"\\nDone.\")"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Seed: 1244\n",
            "\"    conversation dropped and the party sat silent for a minute while alic \"\n",
            "esesyyyssssyyyyyyyyyyyyyyndsnddaatttterseyyyyeddatotgdddtdstttessgryyyyyesneskyyyyesnessyyypdsngsgdrstndstgsyyyedrrngddaatstdrsesedrdsynsndsstyysessnyyyyyesngskyyyyyessgyyyyysesnngdddttttessgsyyyysnnngddaatxttesserryyyyessesyyyyyessnyyyyyesngskygdrfyyutessnnngdddttttessnyyyessesryyyynsnngddaatdrsssessyyeddaatotgdddttttesseryyyyyyyyyyyyyndddatneeysyyessedrsyyesneskyyyyynsndsnyyyyessesyyyysnnngdddtsttessgstyyyedrnddaatotessersedrsyypsndsngtyyyessesryyyyessnyyyyyesngskyyyyynsnngddystyysessgyyyyysnn\n",
            "Done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "prJl7OqPzQYV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}